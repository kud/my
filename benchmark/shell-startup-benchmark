#!/usr/bin/env zsh

# Shell startup performance benchmarking script
# Measures .zshrc loading time and shell initialization performance

set -euo pipefail

source $MY/core/helper

BENCHMARK_DIR="$MY/benchmark/results"
BRANCH_NAME="${1:-$(git branch --show-current)}"
BRANCH_NAME_CLEAN=$(echo "$BRANCH_NAME" | sed 's/\//_/g')  # Replace / with _ for file names
TIMESTAMP=$(date '+%Y%m%d_%H%M%S')
RESULTS_FILE="$BENCHMARK_DIR/shell_startup_${BRANCH_NAME_CLEAN}_${TIMESTAMP}.json"
ITERATIONS=15

# Create benchmark directory if it doesn't exist
mkdir -p "$BENCHMARK_DIR"

echo_title "âš¡ Shell Startup Performance Benchmark - Branch: $BRANCH_NAME"

# Initialize results file
cat > "$RESULTS_FILE" << EOF
{
  "branch": "$BRANCH_NAME",
  "timestamp": "$TIMESTAMP",
  "iterations": $ITERATIONS,
  "system_info": {
    "os": "$(uname -s)",
    "os_version": "$(sw_vers -productVersion)",
    "architecture": "$(uname -m)",
    "shell": "$SHELL",
    "zsh_version": "$(zsh --version)"
  },
  "benchmarks": {}
}
EOF

# Function to measure shell startup time
benchmark_shell_startup() {
    local test_name="$1"
    local command="$2"
    local description="$3"

    echo_task_start "Benchmarking: $test_name"
    echo_subtle "$description"

    local times=()
    local total_time=0

    for i in {1..$ITERATIONS}; do
        echo_subtle "Iteration $i/$ITERATIONS"

        # Measure time for shell startup
        local start_time=$(date +%s.%N)
        eval "$command" > /dev/null 2>&1
        local end_time=$(date +%s.%N)

        local duration=$(echo "$end_time - $start_time" | bc -l)
        times+=($duration)
        total_time=$(echo "$total_time + $duration" | bc -l)
    done

    # Calculate statistics
    local avg_time=$(echo "scale=6; $total_time / $ITERATIONS" | bc -l)
    local min_time=$(printf '%s\n' "${times[@]}" | sort -n | head -1)
    local max_time=$(printf '%s\n' "${times[@]}" | sort -n | tail -1)

    # Calculate median
    local sorted_times=($(printf '%s\n' "${times[@]}" | sort -n))
    local median_index=$(echo "$ITERATIONS / 2" | bc)
    local median_time=${sorted_times[$median_index]}

    # Update results file
    local temp_file=$(mktemp)
    jq --arg name "$test_name" \
       --arg desc "$description" \
       --arg avg "$avg_time" \
       --arg min "$min_time" \
       --arg max "$max_time" \
       --arg median "$median_time" \
       --argjson times "$(printf '%s\n' "${times[@]}" | jq -R . | jq -s .)" \
       '.benchmarks[$name] = {
         "description": $desc,
         "average_seconds": ($avg | tonumber),
         "min_seconds": ($min | tonumber),
         "max_seconds": ($max | tonumber),
         "median_seconds": ($median | tonumber),
         "all_times": $times
       }' "$RESULTS_FILE" > "$temp_file"
    mv "$temp_file" "$RESULTS_FILE"

    echo_success "Average: ${avg_time}s (min: ${min_time}s, max: ${max_time}s)"
    echo_task_done "Benchmark: $test_name"
}

echo_space
echo_title "ðŸš€ Shell Startup Benchmarks"

# Test 1: Basic zsh startup (no rc files)
benchmark_shell_startup "zsh_no_rc" \
    "zsh -c 'exit'" \
    "Basic zsh startup without loading any rc files"

# Test 2: Zsh with system rc only
benchmark_shell_startup "zsh_system_rc" \
    "zsh --no-rcs -c '. /etc/zshrc 2>/dev/null || true; exit'" \
    "Zsh startup with system rc files only"

# Test 3: Full zsh startup (your .zshrc)
benchmark_shell_startup "zsh_full_startup" \
    "zsh -i -c 'exit'" \
    "Full zsh interactive startup with your .zshrc"

# Test 4: Zsh with login shell
benchmark_shell_startup "zsh_login_startup" \
    "zsh -l -c 'exit'" \
    "Zsh login shell startup"

# Test 5: Command execution after startup
benchmark_shell_startup "zsh_with_command" \
    "zsh -i -c 'echo test'" \
    "Zsh startup + simple command execution"

# Test 6: Environment variable loading
benchmark_shell_startup "env_loading" \
    "zsh -i -c 'env | wc -l'" \
    "Environment variable loading performance"

echo_space
echo_title "âš™ï¸ Configuration Component Benchmarks"

# Test individual components if they exist
if [[ -f "$HOME/.zshrc" ]]; then
    # Test p10k instant prompt (if using powerlevel10k)
    if grep -q "p10k-instant-prompt" "$HOME/.zshrc"; then
        benchmark_shell_startup "p10k_instant_prompt" \
            "zsh -c 'source ~/.config/zsh/p10k-instant-prompt.zsh 2>/dev/null || true; exit'" \
            "Powerlevel10k instant prompt loading"
    fi

    # Test prezto loading (if using prezto)
    if grep -q "prezto" "$HOME/.zshrc"; then
        benchmark_shell_startup "prezto_loading" \
            "zsh -c 'source ~/.zprezto/init.zsh 2>/dev/null || true; exit'" \
            "Prezto framework loading"
    fi
fi

# Test your custom helper loading
if [[ -f "$MY/core/helper" ]]; then
    benchmark_shell_startup "my_helper_loading" \
        "zsh -c 'source $MY/core/helper; exit'" \
        "Your custom helper functions loading"
fi

echo_space
echo_title "ðŸ“Š Performance Analysis"

# Calculate overall performance metrics
total_benchmarks=$(jq '.benchmarks | length' "$RESULTS_FILE")
fastest_test=$(jq -r '.benchmarks | to_entries | min_by(.value.average_seconds) | .key' "$RESULTS_FILE")
fastest_time=$(jq -r '.benchmarks | to_entries | min_by(.value.average_seconds) | .value.average_seconds' "$RESULTS_FILE")
slowest_test=$(jq -r '.benchmarks | to_entries | max_by(.value.average_seconds) | .key' "$RESULTS_FILE")
slowest_time=$(jq -r '.benchmarks | to_entries | max_by(.value.average_seconds) | .value.average_seconds' "$RESULTS_FILE")

echo_info "Total benchmarks: $total_benchmarks"
echo_success "Fastest: $fastest_test (${fastest_time}s)"
echo_warn "Slowest: $slowest_test (${slowest_time}s)"

# Show all results in a table
echo_space
echo_title "ðŸ“‹ Complete Results"
echo "| Test | Avg (s) | Min (s) | Max (s) | Median (s) |"
echo "|------|---------|---------|---------|------------|"

jq -r '.benchmarks | to_entries | sort_by(.value.average_seconds) | .[] |
  "| \(.key) | \(.value.average_seconds | tonumber | . * 1000 | round / 1000) | \(.value.min_seconds | tonumber | . * 1000 | round / 1000) | \(.value.max_seconds | tonumber | . * 1000 | round / 1000) | \(.value.median_seconds | tonumber | . * 1000 | round / 1000) |"' "$RESULTS_FILE"

echo_space
echo_success "Shell startup benchmark completed!"
echo_info "Results saved to: $RESULTS_FILE"

# Show the most important metric
full_startup_time=$(jq -r '.benchmarks.zsh_full_startup.average_seconds // "N/A"' "$RESULTS_FILE")
if [[ "$full_startup_time" != "N/A" ]]; then
    echo_space
    echo_title "âš¡ Key Metric: Full Shell Startup Time"
    echo_success "Average startup time: ${full_startup_time}s"

    # Categorize performance
    if (( $(echo "$full_startup_time < 0.1" | bc -l) )); then
        echo_success "ðŸš€ Excellent performance (< 0.1s)"
    elif (( $(echo "$full_startup_time < 0.3" | bc -l) )); then
        echo_info "âœ… Good performance (< 0.3s)"
    elif (( $(echo "$full_startup_time < 0.5" | bc -l) )); then
        echo_warn "âš ï¸  Acceptable performance (< 0.5s)"
    else
        echo_warn "ðŸŒ Slow performance (> 0.5s) - consider optimizations"
    fi
fi
